{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the os module to interact with the operating system\n",
    "import os\n",
    "\n",
    "# Import the llama_index library \n",
    "import llama_index\n",
    "\n",
    "# Import the load_dotenv function from the dotenv library to load environment variables from a .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import the openai library to interact with OpenAI's API\n",
    "import openai\n",
    "\n",
    "# Load environment variables from a .env file into the environment\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below sets the 'OPENAI_API_KEY' environment variable in the operating system environment to the value retrieved from the .env file using os.getenv('OPENAI_API_KEY'). This ensures that the OpenAI API key is available for use in your script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the 'OPENAI_API_KEY' environment variable in the current environment to the value retrieved from the environment variables\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "# openai.api_key = 'sk-...tTM7'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the VectorStoreIndex and SimpleDirectoryReader classes from the llama_index.core module\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "# Create an instance of SimpleDirectoryReader to read files from the \"data\" directory\n",
    "pdfs = SimpleDirectoryReader(\"data\").load_data()\n",
    "\n",
    "# The load_data() method reads and loads the data from the specified directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This snippet imports the necessary classes from the llama_index.core module and uses SimpleDirectoryReader to load data (presumably PDF files) from the \"data\" directory. The loaded data is stored in the pdfs variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raktim\\anaconda3\\envs\\LLM_2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Parsing nodes: 100%|██████████| 547/547 [00:01<00:00, 534.16it/s]\n",
      "Generating embeddings: 100%|██████████| 642/642 [00:07<00:00, 81.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of VectorStoreIndex from the documents loaded into pdfs\n",
    "# The from_documents method is used to build the index from the provided documents\n",
    "# The show_progress parameter, when set to True, displays the progress of the indexing process\n",
    "index = VectorStoreIndex.from_documents(pdfs, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x28a9d92fe80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index # Created the VectorStoreIndex in the form of Word Embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the VectorStoreIndex instance into a query engine\n",
    "# The as_query_engine method prepares the index to handle queries\n",
    "# query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line converts the VectorStoreIndex instance into a query engine using the as_query_engine method, which prepares the index to handle queries. The resulting query engine is stored in the query_engine variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpostprocessor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimilarityPostprocessor\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Create an instance of VectorIndexRetriever with the index and set similarity_top_k to 4\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# This specifies that the retriever should return the top 4 most similar documents for a query\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m retriever \u001b[38;5;241m=\u001b[39m VectorIndexRetriever(index\u001b[38;5;241m=\u001b[39m\u001b[43mindex\u001b[49m, similarity_top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Create an instance of SimilarityPostprocessor with a similarity_cutoff of 0.70\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# This postprocessor will filter out results with a similarity score below 0.70\u001b[39;00m\n\u001b[0;32m     16\u001b[0m postprocessor \u001b[38;5;241m=\u001b[39m SimilarityPostprocessor(similarity_cutoff\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.70\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "# Import the VectorIndexRetriever class from the llama_index.core.retrievers module\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "\n",
    "# Import the RetrieverQueryEngine class from the llama_index.core.query_engine module\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# Import the SimilarityPostprocessor class from the llama_index.core.indices.postprocessor module\n",
    "from llama_index.core.indices.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "# Create an instance of VectorIndexRetriever with the index and set similarity_top_k to 4\n",
    "# This specifies that the retriever should return the top 4 most similar documents for a query\n",
    "retriever = VectorIndexRetriever(index=index, similarity_top_k=4)\n",
    "\n",
    "# Create an instance of SimilarityPostprocessor with a similarity_cutoff of 0.70\n",
    "# This postprocessor will filter out results with a similarity score below 0.70\n",
    "postprocessor = SimilarityPostprocessor(similarity_cutoff=0.70)\n",
    "\n",
    "# Create an instance of RetrieverQueryEngine with the specified retriever and postprocessor\n",
    "# The node_postprocessors parameter is used to apply postprocessing steps to the retrieved documents\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    node_postprocessors=[postprocessor]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This snippet sets up a more customized query engine:\n",
    "\n",
    "* VectorIndexRetriever is used to retrieve the top 4 most similar documents based on the query.\n",
    "* SimilarityPostprocessor filters out documents that do not meet a similarity threshold of 0.70.\n",
    "* RetrieverQueryEngine is initialized with the retriever and postprocessor, enabling more refined query results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x28a9da76440>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It acts as a retriever for our queries from our indexes.\n",
    "query_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following snippet uses the query engine to perform a query with the question \"What is a CNN?\" and then prints the response obtained from the query engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A CNN, or Convolutional Neural Network, is a type of neural network that is specifically designed for processing and analyzing visual data, such as images. It consists of neurons with learnable weights and biases, where each neuron receives inputs, performs a dot product operation, and may apply a non-linearity. CNNs are structured to efficiently handle image inputs, allowing for the encoding of specific properties into the network architecture. This design choice leads to more effective implementation of the forward function and a reduction in the number of parameters in the network compared to traditional neural networks.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is a CNN?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Recurrent Neural Network (RNN) is a type of neural network that is designed to operate over sequences of vectors. Unlike Vanilla Neural Networks, which accept fixed-sized inputs and produce fixed-sized outputs using a fixed number of computational steps, RNNs can process sequences in the input, output, or both. This capability allows RNNs to learn patterns and dependencies in sequential data, making them particularly effective for tasks involving sequences like text generation, speech recognition, and time series prediction.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is a RNN?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Transformer model architecture consists of an encoder and a decoder. The encoder is made up of a stack of identical layers, each containing two sub-layers: a multi-head self-attention mechanism and a position-wise fully connected feed-forward network. Residual connections and layer normalization are applied around each sub-layer. The decoder also consists of a stack of identical layers, with an additional third sub-layer that performs multi-head attention over the output of the encoder stack. The self-attention mechanism in the decoder is modified to prevent positions from attending to subsequent positions. This architecture allows for parallelization and draws global dependencies between input and output using self-attention without relying on recurrent neural networks or convolution.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Explain the transformer architecture.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Is All You Need is a paper that introduces a new network architecture called the Transformer, which is based solely on attention mechanisms. This architecture eliminates the need for complex recurrent or convolutional neural networks typically used in sequence transduction models. The Transformer model has shown superior quality in machine translation tasks, is more parallelizable, and requires significantly less training time compared to existing models.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is Attention is All You Need?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Response: Attention Is All You Need is a paper that introduces a\n",
      "new network architecture called the Transformer, which is based solely\n",
      "on attention mechanisms. This architecture eliminates the need for\n",
      "complex recurrent or convolutional neural networks typically used in\n",
      "sequence transduction models. The Transformer model has shown superior\n",
      "quality in machine translation tasks, is more parallelizable, and\n",
      "requires significantly less training time compared to existing models.\n",
      "______________________________________________________________________\n",
      "Source Node 1/4\n",
      "Node ID: 8549d20a-b81f-4927-8072-69886d41f63e\n",
      "Similarity: 0.8405749229591184\n",
      "Text: Provided proper attribution is provided, Google hereby grants\n",
      "permission to reproduce the tables and figures in this paper solely\n",
      "for use in journalistic or scholarly works. Attention Is All You Need\n",
      "Ashish Vaswani∗ Google Brain avaswani@google.comNoam Shazeer∗ Google\n",
      "Brain noam@google.comNiki Parmar∗ Google Research\n",
      "nikip@google.comJakob Uszkor...\n",
      "______________________________________________________________________\n",
      "Source Node 2/4\n",
      "Node ID: c6df8ceb-4914-4e20-a7a5-b6d8ef75c975\n",
      "Similarity: 0.8119735240630422\n",
      "Text: [25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice\n",
      "Santorini. Building a large annotated corpus of english: The penn\n",
      "treebank. Computational linguistics , 19(2):313–330, 1993. [26] David\n",
      "McClosky, Eugene Charniak, and Mark Johnson. Effective self-training\n",
      "for parsing. In Proceedings of the Human Language Technology\n",
      "Conference of the NA...\n",
      "______________________________________________________________________\n",
      "Source Node 3/4\n",
      "Node ID: f37eceba-169a-4e4a-8b3f-c3478b450a90\n",
      "Similarity: 0.8101096564928035\n",
      "Text: Input-Input Layer5 The Law will never be perfect , but its\n",
      "application should be just - this is what we are missing , in my\n",
      "opinion . <EOS> <pad> The Law will never be perfect , but its\n",
      "application should be just - this is what we are missing , in my\n",
      "opinion . <EOS> <pad> Input-Input Layer5 The Law will never be perfect\n",
      ", but its application sho...\n",
      "______________________________________________________________________\n",
      "Source Node 4/4\n",
      "Node ID: 3a515890-c102-479d-909d-76394ace27d6\n",
      "Similarity: 0.8095217911582211\n",
      "Text: InInternational Conference on Learning Representations , 2017.\n",
      "[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic\n",
      "optimization. In ICLR , 2015. [21] Oleksii Kuchaiev and Boris\n",
      "Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\n",
      "arXiv:1703.10722 , 2017. [22] Zhouhan Lin, Minwei Feng, Cicero\n",
      "Nogueira dos Santos, Mo Yu, B...\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "\n",
    "pprint_response(response, show_source=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper \"Attention Is All You Need\" introduces a new network architecture called the Transformer, which relies solely on attention mechanisms, eliminating the need for recurrent or convolutional neural networks in sequence transduction models. By connecting the encoder and decoder through attention, the Transformer model proves to be more efficient, parallelizable, and quicker to train compared to existing models. Experimental results on machine translation tasks demonstrate the Transformer's superiority in quality, achieving significant improvements in BLEU scores on tasks like English-to-German and English-to-French translations. The model's success extends beyond translation tasks, showing promising results in English constituency parsing as well. The paper highlights the benefits of self-attention, such as improved computational performance for long sequences and potentially more interpretable models. Through detailed training procedures, hardware specifications, and optimization techniques like the Adam optimizer with a specific learning rate schedule, the paper provides a comprehensive overview of the Transformer model's development and performance.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules and classes\n",
    "import os.path\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,  # For creating and handling vector store indices\n",
    "    SimpleDirectoryReader,  # For reading documents from a directory\n",
    "    StorageContext,  # For managing storage contexts\n",
    "    load_index_from_storage,  # For loading an index from storage\n",
    ")\n",
    "\n",
    "# Define the directory where the storage will be persisted\n",
    "PERSIST_DIR = \"./storage\"\n",
    "\n",
    "# Check if the storage directory already exists\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    # If the storage directory does not exist, load the documents and create the index\n",
    "    documents = SimpleDirectoryReader(\"data\").load_data()  # Read documents from the \"data\" directory\n",
    "    index = VectorStoreIndex.from_documents(documents)  # Create an index from the loaded documents\n",
    "    \n",
    "    # Store the created index for later use\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "else:\n",
    "    # If the storage directory exists, load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)  # Create a storage context from the existing directory\n",
    "    index = load_index_from_storage(storage_context)  # Load the index from the storage context\n",
    "\n",
    "# Create a query engine from the index, regardless of whether it was newly created or loaded from storage\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# Query the index with a specific question\n",
    "response = query_engine.query(\"Summarize Attention is all you need in 250 words.\")\n",
    "\n",
    "# Print the response from the query engine\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imports:\n",
    "\n",
    "Various components from the llama_index.core module are imported to handle vector indices, reading documents, managing storage contexts, and loading indices from storage.\n",
    "\n",
    "2. Storage Check and Index Creation/Loading:\n",
    "\n",
    "The script checks if a directory (./storage) exists to determine if a previously stored index is available.\n",
    "If the directory does not exist, it reads documents from the data directory, creates an index from these documents, and persists the index.\n",
    "If the directory exists, it loads the index from the stored context.\n",
    "\n",
    "3. Query Engine:\n",
    "\n",
    "Whether the index is newly created or loaded from storage, it is converted into a query engine.\n",
    "A query is made to the index asking, \"What are transformers?\", and the response is printed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
